{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"fashion_mnist_denoise.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"id":"0o8MSbeQKD74","outputId":"9927f625-0aa4-4c85-8242-90e76d75077b"},"source":["import keras \n","from keras.datasets import fashion_mnist\n","import matplotlib.pyplot as plt\n","from keras.models import Sequential,Model\n","from tensorflow.keras.layers import Input, Dense, Activation,Conv2D,MaxPooling2D,Dropout,Flatten,Reshape,UpSampling2D,Deconvolution2D,Conv2DTranspose\n","import numpy as np\n","from keras.callbacks import TensorBoard\n","%matplotlib inline"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-48979ed65602>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mUpSampling2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDeconvolution2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mConv2DTranspose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'Deconvolution2D'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"05atecoAKD7-","outputId":"6465989c-0a05-4955-9dd0-241d350ca788"},"source":["(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","8192/5148 [===============================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":231},"id":"zr6X7upCKD7-","outputId":"ebef4e31-8793-492b-dbfb-064d6a8c002f"},"source":["input_img = Input(shape=(28,28,1))\n","#encoder\n","l1 = Conv2D(16, (3,3),strides = 1 , activation = 'relu',padding='same')(input_img)\n","l1 = MaxPooling2D((2,2))(l1)\n","l1 = Conv2D(8,(3,3),strides = 1, activation='relu',padding='same')(l1)\n","l1 = MaxPooling2D((2,2),padding = 'same')(l1)\n","#\n","l1 = Conv2D(8,(3,3),strides = 1,activation = 'relu',padding='same')(l1)\n","#decoder network\n","l1 = Conv2DTranspose(8,(3,3),strides = 1,activation='relu',padding='same')(l1)\n","l1 = UpSampling2D((2,2))(l1)\n","l1 = Conv2DTranspose(16,(3,3),strides = 1,activation='relu',padding = 'same')(l1)\n","l1 = UpSampling2D((2,2))(l1)\n","l2 = Conv2DTranspose(1,(3,3),strides = 1, activation='sigmoid',padding  ='same')(l1)\n","\n","model2 = Model(input_img, l2)\n","model2.compile(optimizer='Adam', loss='binary_crossentropy')\n","model2.summary()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-8d3639a3de44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#decoder network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2DTranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUpSampling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2DTranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Conv2DTranspose' is not defined"]}]},{"cell_type":"code","metadata":{"id":"XAFM0WguKD7_"},"source":["x_train_1=x_train/255.0\n","from time import time\n","tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XXq4sj0yKD7_"},"source":["x_train_ = x_train_1 + 0.3 * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n","x_train_ = np.clip(x_train_, 0., 1.)\n","x_ = x_train_[:,:,:,np.newaxis]\n","x_.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rSFcxiR_KD8A"},"source":["np.max(x_[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"15z40_m7KD8A"},"source":["plt.imshow(np.reshape(x_train_[500],(28,28)),cmap='Greys')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vbnJKLrrKD8A"},"source":["x_train.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xfaFC42-KD8A"},"source":["model2.fit(x_, x_train_1[:,:,:,np.newaxis], epochs = 10, batch_size = 256, callbacks = [tensorboard])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O-ZIs1vWKD8B"},"source":["pp = model2.predict(np.reshape(x_[0],(1,28,28,1)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZV_8ZP5bKD8B"},"source":["pp = np.reshape(pp,(28,28))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pqLrs9eYKD8B"},"source":["## reconstructed Image"]},{"cell_type":"code","metadata":{"id":"1AxMJgj2KD8B"},"source":["plt.imshow(pp,cmap='Greys')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z4llBAl-KD8B"},"source":["## "]},{"cell_type":"code","metadata":{"id":"9UbjBos_KD8C"},"source":["plt.imshow(np.reshape(x_[0],(28,28)),cmap='Greys')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9o6RkJJJKD8C"},"source":["plt.imshow(x_train[0],cmap='Greys')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BXY4hs0lKD8C"},"source":[""],"execution_count":null,"outputs":[]}]}